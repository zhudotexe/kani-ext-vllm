"""
Ensure that the tokens generated by the offline vLLM engine are the same as the tokens in the API mode.

We do this by just spinning up one of each and seeing what it outputs. This runs on CPU, so we use a tiny model.
"""

import random

from kani import Kani
from kani.ext.vllm import VLLMEngine, VLLMOpenAIEngine, VLLMServerEngine
from vllm import SamplingParams

MODEL_ID = "meta-llama/Llama-3.2-1B-Instruct"
# random prompts
PROMPTS = [
    "Tell me about the Boeing 737.",
    "Without using the Shinkansen, how do I get from Oku-Tama to Komagome?",
    "Help me come up with a new magic item for D&D called the Blade of Kani.",
    "How do I set up vLLM?",
    "Please output as many of the letter 'a' as possible.",
    "How many 'a's are in the word 'strawberry'?",
]


# define engines to test with
async def offline(seed, prompt):
    model = VLLMEngine(
        model_id=MODEL_ID,
        max_context_size=8192,
        model_load_kwargs={"seed": seed},
        sampling_params=SamplingParams(temperature=0, max_tokens=2048),
    )
    ai = Kani(model)

    resp = await ai.chat_round_str(prompt)
    await model.close()
    del model
    return resp


async def api(seed, prompt):
    model = VLLMServerEngine(
        model_id=MODEL_ID,
        max_context_size=8192,
        vllm_args={"seed": seed},
        timeout=3000,
        temperature=0,
        max_tokens=2048,
    )
    ai = Kani(model)

    resp = await ai.chat_round_str(prompt)
    await model.close()
    del model
    return resp


async def openai(seed, prompt):
    model = VLLMOpenAIEngine(
        model_id=MODEL_ID,
        max_context_size=8192,
        vllm_args={"seed": seed},
        timeout=3000,
        temperature=0,
        max_tokens=2048,
    )
    ai = Kani(model)

    resp = await ai.chat_round_str(prompt)
    await model.close()
    del model
    return resp


# pairwise equivalence tests
async def test_equivalence_offline_api():
    seed = random.randint(0, 99999)
    prompt = random.choice(PROMPTS)
    resp1 = await offline(seed, prompt)
    print(f"OFFLINE: {resp1}")
    resp2 = await api(seed, prompt)
    print(f"API: {resp2}")
    assert resp1 == resp2


async def test_equivalence_offline_openai():
    seed = random.randint(0, 99999)
    prompt = random.choice(PROMPTS)
    resp1 = await offline(seed, prompt)
    print(f"OFFLINE: {resp1}")
    resp2 = await openai(seed, prompt)
    print(f"OPENAI: {resp2}")
    assert resp1 == resp2


async def test_equivalence_api_openai():
    seed = random.randint(0, 99999)
    prompt = random.choice(PROMPTS)
    resp1 = await api(seed, prompt)
    print(f"API: {resp1}")
    resp2 = await openai(seed, prompt)
    print(f"OPENAI: {resp2}")
    assert resp1 == resp2
